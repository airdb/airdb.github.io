(window.webpackJsonp=window.webpackJsonp||[]).push([[109],{219:function(t,a,e){"use strict";e.r(a);var r=e(0),n=Object(r.a)({},(function(){var t=this,a=t.$createElement,e=t._self._c||a;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h1",{attrs:{id:"算法"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#算法"}},[t._v("#")]),t._v(" 算法")]),t._v(" "),e("p",[t._v("机器学习算法有很多，大概有，回归算法、基于实例的算法、正则化算法、决策树算法、贝叶斯算法、基于核的算法、聚类算法、关联规则学习、人工神经网络算法、深度学习算法、降低维度算法、集成算法，下面将几个常见的机器学习算法，进行详述：")]),t._v(" "),e("p",[t._v("决策树算法，根据数据的属性采用树状结构建立决策模型$常常用来解决分类和回归问题。\n优点：计算量比较简单，解释性强，比较适合处理有缺失属性值的数据样本，能够处理不相关的特征。\n缺点：容易过拟合（后续出现了随机森林，减小了过拟合现象）。")]),t._v(" "),e("p",[t._v("贝叶斯算法，基于贝叶斯定理的一类算法，主要用来解决分类和回归问题。\n优点：对小规模的数据表现很好，适合多分类任务，适合增量式训练。\n缺点：对输入数据的表达形式很敏感，对关联性强的特征表现不好。")]),t._v(" "),e("p",[t._v("朴素贝叶斯分类\nhttps://www.zhihu.com/question/27306416")]),t._v(" "),e("h2",{attrs:{id:"算法模型"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#算法模型"}},[t._v("#")]),t._v(" 算法模型")]),t._v(" "),e("h3",{attrs:{id:"回归算法"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#回归算法"}},[t._v("#")]),t._v(" 回归算法")]),t._v(" "),e("pre",[e("code",[t._v("    线性回归\n    逻辑回归\n    多元自适应回归(MARS)\n    本地散点平滑估计(LOESS)\n")])]),t._v(" "),e("h3",{attrs:{id:"基于实例的学习算法"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#基于实例的学习算法"}},[t._v("#")]),t._v(" 基于实例的学习算法")]),t._v(" "),e("pre",[e("code",[t._v("    K-邻近算法（KNN）\n    学习矢量化（LVQ）\n    自组织映射算法（SOM）\n    局部加权学习算法（LWL）\n")])]),t._v(" "),e("h3",{attrs:{id:"正则化算法"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#正则化算法"}},[t._v("#")]),t._v(" 正则化算法")]),t._v(" "),e("pre",[e("code",[t._v("    岭回归（Ridge Regression）\n    LASSO（Least Absolute Shrinkage and Selection Operator）\n    Elastic Net\n    最小角回归（LARS）\n")])]),t._v(" "),e("h3",{attrs:{id:"决策树算法"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#决策树算法"}},[t._v("#")]),t._v(" 决策树算法")]),t._v(" "),e("pre",[e("code",[t._v("    分类和回归树（CART）\n    ID3算法(Iterative Dichotomiser 3)\n    CHAID（Chi-squared Automatic Interaction Detection\n    随机森林（Random Forest）\n    多元自适应回归样条（MARS）\n    梯度推进机（Gradient Boosting Machine， GBM）\n")])]),t._v(" "),e("h3",{attrs:{id:"贝叶斯算法"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#贝叶斯算法"}},[t._v("#")]),t._v(" 贝叶斯算法")]),t._v(" "),e("pre",[e("code",[t._v("    朴素贝叶斯\n    高斯朴素贝叶斯\n    多项式朴素贝叶斯\n    AODE（Averaged One-Dependence Estimators）\n    贝叶斯网络（Bayesian Belief Network）\n")])]),t._v(" "),e("h3",{attrs:{id:"基于核的算法"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#基于核的算法"}},[t._v("#")]),t._v(" 基于核的算法")]),t._v(" "),e("pre",[e("code",[t._v("    支持向量机（SVM）\n    径向基函数（Radial Basis Function ，RBF)\n    线性判别分析（Linear Discriminate Analysis ，LDA)\n")])]),t._v(" "),e("h3",{attrs:{id:"聚类算法"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#聚类算法"}},[t._v("#")]),t._v(" 聚类算法")]),t._v(" "),e("pre",[e("code",[t._v("    K-均值\n    K-中位数\n    EM算法\n    分层聚类\n")])]),t._v(" "),e("h3",{attrs:{id:"关联规则学习"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#关联规则学习"}},[t._v("#")]),t._v(" 关联规则学习")]),t._v(" "),e("pre",[e("code",[t._v("    Apriori算法\n    Eclat算法\n")])]),t._v(" "),e("h3",{attrs:{id:"神经网络"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#神经网络"}},[t._v("#")]),t._v(" 神经网络")]),t._v(" "),e("pre",[e("code",[t._v("    感知器\n    反向传播算法（BP）\n    Hopfield网络\n    径向基函数网络（RBFN）\n")])]),t._v(" "),e("h3",{attrs:{id:"深度学习"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#深度学习"}},[t._v("#")]),t._v(" 深度学习")]),t._v(" "),e("pre",[e("code",[t._v("    深度玻尔兹曼机（DBM）\n    卷积神经网络（CNN）\n    递归神经网络（RNN、LSTM）\n    栈式自编码算法（Stacked Auto-Encoder）\n")])]),t._v(" "),e("h3",{attrs:{id:"降维算法"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#降维算法"}},[t._v("#")]),t._v(" 降维算法")]),t._v(" "),e("pre",[e("code",[t._v("    主成分分析法（PCA）\n    主成分回归（PCR）\n    偏最小二乘回归（PLSR）\n    萨蒙映射\n    多维尺度分析法（MDS\n    投影寻踪法（PP）\n    线性判别分析法（LDA）\n    混合判别分析法（MDA）\n    二次判别分析法（QDA）\n    灵活判别分析法（Flexible Discriminant Analysis，FDA\n")])]),t._v(" "),e("h3",{attrs:{id:"集成算法"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#集成算法"}},[t._v("#")]),t._v(" 集成算法")]),t._v(" "),e("pre",[e("code",[t._v("    Boosting\n    Bagging\n    AdaBoost\n    堆叠泛化（混合）\n    GBM 算法\n    GBRT 算法\n    随机森林\n")])]),t._v(" "),e("h3",{attrs:{id:"其他算法"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#其他算法"}},[t._v("#")]),t._v(" 其他算法")]),t._v(" "),e("pre",[e("code",[t._v("    特征选择算法\n    性能评估算法\n    自然语言处理\n    计算机视觉\n    推荐系统\n    强化学习\n    迁移学习\n")])]),t._v(" "),e("p",[e("a",{attrs:{href:"https://github.com/KeKe-Li/tutorial/blob/master/assets/src/",target:"_blank",rel:"noopener noreferrer"}},[t._v("来源"),e("OutboundLink")],1)]),t._v(" "),e("h2",{attrs:{id:"入门文档"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#入门文档"}},[t._v("#")]),t._v(" 入门文档")]),t._v(" "),e("p",[e("a",{attrs:{href:"http://mp.weixin.qq.com/s/fqjFjxwRwrDJ0JFAkHuZlA",target:"_blank",rel:"noopener noreferrer"}},[t._v("十大经典算法入门"),e("OutboundLink")],1)])])}),[],!1,null,null,null);a.default=n.exports}}]);